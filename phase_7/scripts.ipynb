{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65e8876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pytorch_lightning as pl\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f1c21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            d_model: モデルの隠れ層の次元数\n",
    "            dropout: ドロップアウト率\n",
    "            max_len: 想定される入力シーケンス最大長\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Positional Encoding行列[max_len, d_model]の初期化\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "\n",
    "        # 位置情報のベクトル\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "\n",
    "        # 10000^(2i/d_model)の計算\n",
    "        # 対数空間で計算してからexpで戻すことで数値安定性を確保\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "\n",
    "        # 偶数次元にsin、奇数次元にcosを適用\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        # バッチ次元を追加してshapeを[1, max_len, d_model]に変形\n",
    "        pe = pe.unsqueeze(0)\n",
    "\n",
    "        # モデルのパラメータとして登録（学習されない）\n",
    "        # state_dictに保存されるが、勾配計算optimizerの対象にはならない\n",
    "        self.register_buffer('pe', pe)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Enbeddingされた入力テンソル、shapeは[batch_size, seq_len, d_model]\n",
    "        \n",
    "        Returns:\n",
    "            Positional Encodingが加算されたテンソル、shapeは[batch_size, seq_len, d_model]\n",
    "        \"\"\"\n",
    "        # 入力テンソルの長さに合わせてPositional Encodingをスライスして加算\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "\n",
    "        # ドロップアウトを適用して出力\n",
    "        return self.dropout(x)\n",
    "    \n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model: int, num_heads: int, dropout: float = 0.1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            d_model (int): モデルの隠れ層の次元数\n",
    "            num_heads (int): ヘッドの数\n",
    "            dropout (float, optional): ドロップアウト率. Defaults to 0.1.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # d_modelがnum_headsで割り切れることを確認\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads # 各ヘッドの次元数\n",
    "\n",
    "        # Q, K, Vの線形変換\n",
    "        # 実際には全ヘッド分を一度に計算するため、出力次元はd_modelのまま\n",
    "        self.w_q = nn.Linear(d_model, d_model)\n",
    "        self.w_k = nn.Linear(d_model, d_model)\n",
    "        self.w_v = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.fc_out = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, query: torch.Tensor, key: torch.Tensor, value: torch.Tensor, mask: torch.Tensor = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            query (torch.Tensor): [batch_size, seq_len, d_model]\n",
    "            key (torch.Tensor):   [batch_size, seq_len, d_model]\n",
    "            value (torch.Tensor): [batch_size, seq_len, d_model]\n",
    "            mask (torch.Tensor, optional): [batch_size, 1, 1, seq_len] または [batch_size, 1, seq_len, seq_len]\n",
    "                                           (0: マスクなし、1: マスクありなどの定義によるが、ここでは加算マスクを想定)\n",
    "                                           Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: [batch_size, seq_len, d_model]\n",
    "        \"\"\"\n",
    "        batch_size = query.size(0)\n",
    "\n",
    "        # 1. 線形変換\n",
    "        # [batch_size, seq_len, d_model] -> [batch_size, seq_len, num_heads]\n",
    "        Q = self.w_q(query)\n",
    "        K = self.w_k(key)\n",
    "        V = self.w_v(value)\n",
    "\n",
    "        # 2. ヘッドの分割\n",
    "        # [batch_size, seq_len, num_heads] -> [batch_size, seq_len, num_heads, d_k]\n",
    "        # その後、計算しやすいようにヘッドの次元を先頭に移動させる(転置) -> [batch_size, num_heads, seq_len, d_k]\n",
    "        Q = Q.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        K = K.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        V = V.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "        # 3. Scaled Dot-Product Attention\n",
    "        # 3.1. スコアの計算 Q * K^T / sqrt(d_k)\n",
    "        # Q: [..., seq_len_q, d_k], K^T: [..., d_k, seq_len_k] -> scores: [..., seq_len_q, seq_len_k]\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "\n",
    "        # 3.2. マスクの適用(optional)\n",
    "        if mask is not None:\n",
    "            # ここではマスクが0の場所を非常に小さい値(-1e9)でマスクすると仮定\n",
    "            # 実装により1と0の定義が異なる場合があるため注意する\n",
    "            # 非常に小さい値(-1e9)で埋めることで、softmax後にほぼ0になるようにする\n",
    "            # scores = scores.masked_fill(mask == 0, -1e9)\n",
    "            scores = scores + mask # 加算マスクの場合 (maskが0の場所に-1e9が入っている想定)\n",
    "        \n",
    "        # 3.3. softmax & dropout\n",
    "        attention_weights = torch.softmax(scores, dim=-1)\n",
    "        attention_weights = self.dropout(attention_weights)\n",
    "\n",
    "        # 3.4. Valueとの積\n",
    "        # attention_weights: [..., seq_len_q, seq_len_k] * V: [..., seq_len_k, d_k] -> [...,seq_lenn_q, d_k]\n",
    "        output = torch.matmul(attention_weights, V)\n",
    "\n",
    "        # 4. ヘッドの結合\n",
    "        # [batch_size, num_beads, seq_len, d_k] -> [batch_size, seq_len, num_heads, d_k]\n",
    "        output = output.transpose(1, 2).contiguous()\n",
    "\n",
    "        # [batch_size, seq_len, d_model]に戻す\n",
    "        output = output.view(batch_size, -1, self.d_model)\n",
    "\n",
    "        # 5. 線形変換\n",
    "        output = self.fc_out(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model: int, d_ff: int, dropout: float = 0.1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            d_model (int): モデルの次元数\n",
    "            d_ff (int): FFNの中間層の次元数\n",
    "            dropout (float, optional): ドロップアウト率. Defaults to 0.1.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # 一層目 d_model -> d_ff\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        # 二層目 d_ff -> d_model\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        # ドロップアウト\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # 活性化関数 ReLU\n",
    "        # 元論文ではReLUが使われているが、近年のLLMではGELUがよく使われている\n",
    "        self.activation = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (torch.Tensor): [batch_size, seq_len, d_model]\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: [batch_size, seq_len, d_model]\n",
    "        \"\"\"\n",
    "        # Linear -> ReLU -> Dropout -> Linear\n",
    "        # x: [batch_size, seq_len, d_model] -> [batch_size, seq_len, d_ff]\n",
    "        hidden = self.activation(self.w_1(x))\n",
    "        hidden = self.dropout(hidden)\n",
    "\n",
    "        # [batch_size, seq_len, d_ff] -> [batch_size, seq_len, d_model]\n",
    "        output = self.w_2(hidden)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df57b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model: int, num_heads: int, d_ff: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        # 1. Self-Attention layer\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads, dropout)\n",
    "\n",
    "        # 2. Feed-Forward Network layer\n",
    "        self.ffn = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "\n",
    "        # 3. Layer Normalization & Dropout layers\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, mask: torch.Tensor = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): [batch_size, seq_len, d_model]\n",
    "            mask (torch.Tensor, optional): Padding Maskなど. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: [batch_size, seq_len, d_model]\n",
    "        \"\"\"\n",
    "\n",
    "        # 1. Sublayer 1: Self-Attention\n",
    "        # Residual Connection: x + Sublayer(x)\n",
    "        # Post-LN: Norm(x + Sublayer(x))\n",
    "        # Attentionの入出力は同じshape\n",
    "        attn_output = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "\n",
    "        # 2. Sublayer 2: Feed-Forward Network\n",
    "        ffn_output = self.ffn(x)\n",
    "        x = self.norm2(x + self.dropout(ffn_output))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model: int, num_heads: int, d_ff: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        # 1. Masked Self-Attention layer\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads, dropout)\n",
    "\n",
    "        # 2. Cross-Attention layer (Source-Target Attention)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads, dropout)\n",
    "\n",
    "        # 3. Feed-Forward Network layer\n",
    "        self.ffn = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "\n",
    "        # 4. Normalization & Dropout layers\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, memory: torch.Tensor, src_mask: torch.Tensor, tgt_mask: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Decoderへの入力テンソル、shapeは[batch_size, tgt_len, d_model]\n",
    "            memory (torch.Tensor): Encoderの出力テンソル、shapeは[batch_size, src_len, d_model]\n",
    "            src_mask (torch.Tensor): Memoryに対するマスク(Padding Mask)\n",
    "            tgt_mask (torch.Tensor): Self-Attention用のマスク(Look-Ahead Mask + Padding Mask)\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Decoderの出力テンソル、shapeは[batch_size, tgt_len, d_model]\n",
    "        \"\"\"\n",
    "\n",
    "        # 1. Sublayer 1: Masked Self-Attention\n",
    "        # 未来の単語を見ないように tgt_mask を適用\n",
    "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "\n",
    "        # 2. Sublayer 2: Cross-Attention\n",
    "        # Query = x(Decoderの出力), Key = Value = memory(Encoderの出力)\n",
    "        # Encoder側のパディングを見ないように src_mask を適用\n",
    "        attn_output = self.cross_attn(x, memory, memory, src_mask)\n",
    "        x = self.norm2(x + self.dropout(attn_output))\n",
    "\n",
    "        # 3. Sublayer 3: Feed-Forward Network\n",
    "        ffn_output = self.ffn(x)\n",
    "        x = self.norm3(x + self.dropout(ffn_output))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size: int, d_model: int, num_layers: int, num_heads: int, d_ff: int, max_len: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(d_model, dropout, max_len)\n",
    "\n",
    "        # EncoderLayerをnum_layers個積み重ねる\n",
    "        self.layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x: torch.Tensor, mask: torch.Tensor) -> torch.Tensor:\n",
    "        # 1. Embedding & Positional Encoding\n",
    "        # 論文通り sqrt(d_model)でスケーリング\n",
    "        x = self.embedding(x) * math.sqrt(self.d_model)\n",
    "        x = self.pos_encoding(x)\n",
    "\n",
    "        # 2. Apply all layers\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size: int, d_model: int, num_layers: int, num_heads: int, d_ff: int, max_len: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self. pos_encoding = PositionalEncoding(d_model, dropout, max_len)\n",
    "\n",
    "        # DecoderLayerをnum_layers個積み重ねる\n",
    "        self.layers = nn.ModuleList([\n",
    "            DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x: torch.Tensor, memory: torch.Tensor, src_mask: torch.Tensor, tgt_mask: torch.Tensor) -> torch.Tensor:\n",
    "        # 1. Embedding & Positional Encoding\n",
    "        # 論文通り sqrt(d_model)でスケーリング\n",
    "        x = self.embedding(x) * math.sqrt(self.d_model)\n",
    "        x = self.pos_encoding(x)\n",
    "\n",
    "        # 2. Apply all layers\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, src_mask, tgt_mask)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size: int, tgt_vocab_size: int, d_model: int = 512, num_layers: int = 6, num_heads: int = 8, d_ff: int = 2048, max_len: int = 5000, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = Encoder(src_vocab_size, d_model, num_layers, num_heads, d_ff, max_len, dropout)\n",
    "        self.decoder = Decoder(tgt_vocab_size, d_model, num_layers, num_heads, d_ff, max_len, dropout)\n",
    "\n",
    "        # 最終出力層の線形変換(Linear Projection)\n",
    "        self.fc_out = nn.Linear(d_model, tgt_vocab_size)\n",
    "\n",
    "    def forward(self, src: torch.Tensor, tgt: torch.Tensor, src_mask: torch.Tensor = None, tgt_mask: torch.Tensor = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            src (torch.Tensor): [batch, src_len] Encoderへの入力単語ID列\n",
    "            tgt (torch.Tensor): [batch, tgt_len] Decoderへの入力単語ID列\n",
    "            src_mask (torch.Tensor, optional): Encoder用のマスク. Defaults to None.\n",
    "            tgt_mask (torch.Tensor, optional): Decoder用のマスク. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: [batch, tgt_len, tgt_vocab_size] 出力単語の確率分布\n",
    "        \"\"\"\n",
    "\n",
    "        # 1. Encode\n",
    "        # memory: [batch, src_len, d_model]\n",
    "        memory = self.encoder(src, src_mask)\n",
    "\n",
    "        # 2. Decode\n",
    "        # decoder_output: [batch, tgt_len, d_model]\n",
    "        decoder_output = self.decoder(tgt, memory, src_mask, tgt_mask)\n",
    "\n",
    "        # 3. Final linear layer\n",
    "        # logits: [batch, tgt_len, tgt_vocab_size]\n",
    "        logits = self.fc_out(decoder_output)\n",
    "\n",
    "        return logits\n",
    "    \n",
    "    def encode(self, src: torch.Tensor, src_mask: torch.Tensor = None) -> torch.Tensor:\n",
    "        \"\"\"推論時にEncoderのみを動かすためのヘルパー\"\"\"\n",
    "        return self.encoder(src, src_mask)\n",
    "    \n",
    "    def decode(self, tgt: torch.Tensor, memory: torch.Tensor, src_mask: torch.Tensor = None, tgt_mask: torch.Tensor = None) -> torch.Tensor:\n",
    "        \"\"\"推論時にDecoderのみを動かすためのヘルパー\"\"\"\n",
    "        return self.decoder(tgt, memory, src_mask, tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd844b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq: torch.Tensor, pad_idx: int = 0) -> torch.Tensor:\n",
    "    \"\"\"パディングマスクを作成する関数。<pad>の部分を1e-9、それ以外を0にする。\n",
    "\n",
    "    Args:\n",
    "        seq (torch.Tensor): [batch_size, seq_len]の形状を持つテンソル。入力単語のID列\n",
    "        pad_idx (int, optional): パディングを表すID。 Defaults to 0.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: [batch_size, 1, 1, seq_len] Mult-head Attentionのスコアに加算するためのマスク\n",
    "    \"\"\"\n",
    "\n",
    "    # seq == pad_idx の部分はTrue、それ以外はFalse\n",
    "    mask = (seq == pad_idx)\n",
    "\n",
    "    # shapeを [batch_size, 1, 1, seq_len] に変形\n",
    "    # Trueを1e-9、Falseを0に変換\n",
    "    # float型に変換しないと加算時にエラーになる\n",
    "    return mask.unsqueeze(1).unsqueeze(2).float() * -1e9\n",
    "\n",
    "\n",
    "def create_look_ahead_mask(seq_len: int) -> torch.Tensor:\n",
    "    \"\"\"未来の単語を見えなくするための上三角マスクを作成する関数\n",
    "\n",
    "    Args:\n",
    "        seq_len (int): シーケンス長\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: [1, 1, seq_len, seq_len] 対角成分より上が1e-9、それ以外が0の行列\n",
    "    \"\"\"\n",
    "    # torch.triuで上三角行列を取り出す (diagonal=1で対角線のひとつ上から)\n",
    "    mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1)\n",
    "\n",
    "    # マスク部分を1e-9、それ以外を0に変換\n",
    "    return mask.unsqueeze(0).unsqueeze(0).float() * -1e9\n",
    "\n",
    "\n",
    "def create_masks(src: torch.Tensor, tgt: torch.Tensor, pad_idx: int = 0):\n",
    "    \"\"\"EncoderとDecoderに必要なすべてのマスクを一括生成するヘルパー関数\n",
    "\n",
    "    Args:\n",
    "        src (torch.Tensor): [batch_size, src_len]\n",
    "        tgt (torch.Tensor): [batch_size, tgt_len]\n",
    "        pad_idx (int, optional): パディングID。 Defaults to 0.\n",
    "    \"\"\"\n",
    "    # 1. Encoder用のマスク(Padding Maskのみ)\n",
    "    src_mask = create_padding_mask(src, pad_idx)\n",
    "\n",
    "    # 2. Decoder用のマスク(Padding Mask + Look-ahead Mask)\n",
    "    # 2.1. TargetのPadding Mask [batch_size, 1, 1, tgt_len]\n",
    "    tgt_pad_mask = create_padding_mask(tgt, pad_idx)\n",
    "\n",
    "    # 2.2. Look-ahead Mask [1, 1, tgt_len, tgt_len]\n",
    "    tgt_len = tgt.size(1)\n",
    "    look_ahead_mask = create_look_ahead_mask(tgt_len).to(tgt.device)\n",
    "\n",
    "    # 2.3. Padding MaskとLook-ahead Maskを結合 (どちらかが-1e9なら-1e9になるように加算またはmaxを取る)\n",
    "    # ここで単純に和を取ると-2e9になる箇所ができるが、Softmaxにおいては十分小さいので計算には影響しない\n",
    "    # 論理和(OR)的にマスクしたいので、最小値を取る実装もよくある(torch.min)\n",
    "    tgt_mask = torch.min(tgt_pad_mask, look_ahead_mask)\n",
    "\n",
    "    return src_mask, tgt_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0a944d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CopyTaskDataset(Dataset):\n",
    "    def __init__(self, num_samples: int, max_len: int, vocab_size: int):\n",
    "        \"\"\"ランダムな文字列のペア(src, tgt)を生成・保持するデータセットクラス\n",
    "        Args:\n",
    "            num_samples (int): 生成するサンプル数\n",
    "            max_len (int): 各サンプルの最大長\n",
    "            vocab_size (int): 単語IDの語彙数\n",
    "        \"\"\"\n",
    "        self.num_samples = num_samples\n",
    "        self.max_len = max_len\n",
    "        self.vocab_size = vocab_size\n",
    "        self.data = self._generate_data()\n",
    "\n",
    "    def _generate_data(self) -> list:\n",
    "        data = []\n",
    "\n",
    "        # <sos>と<eos>のIDを定義\n",
    "        start_symbol = self.vocab_size\n",
    "        end_symbol = self.vocab_size + 1\n",
    "        for _ in range(self.num_samples):\n",
    "            # 1〜vocab_size-1 のランダムな数列(0はpad, vocab_size+2はstart/end token用に空けておく\n",
    "            seq_len = random.randint(1, self.max_len)\n",
    "\n",
    "            # ランダムな長さの数字列\n",
    "            seq = torch.randint(1, self.vocab_size, (seq_len,))\n",
    "\n",
    "            # Padding処理\n",
    "            # src: [seq_len] -> [max_len] に0埋め\n",
    "            src = torch.zeros(self.max_len + 2, dtype=torch.long)\n",
    "            src[:seq_len] = seq\n",
    "\n",
    "            # tgt: [<sos>, ..., <eos>] -> [max_len + 2] に0埋め\n",
    "            tgt = torch.zeros(self.max_len + 2, dtype=torch.long)\n",
    "            tgt[0] = start_symbol\n",
    "            tgt[1:seq_len + 1] = seq\n",
    "            tgt[seq_len + 1] = end_symbol\n",
    "            # 残りは0でパディングされたまま\n",
    "\n",
    "            data.append((src, tgt))\n",
    "        return data\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return self.num_samples\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> tuple:\n",
    "        # インデックスに対応する(src, tgt)ペアを返す\n",
    "        return self.data[idx]\n",
    "\n",
    "def collate_fn(batch) -> tuple:\n",
    "    \"\"\"DataLoaderがミニバッチを作成する際に呼ばれるコールバック関数\n",
    "\n",
    "    Args:\n",
    "        batch (list): (src, tgt)ペアのリスト [(src1, tgt1), (src2, tgt2), ...]\n",
    "\n",
    "    Returns:\n",
    "        tuple: パディングされたsrcとtgtのテンソル\n",
    "    \"\"\"\n",
    "    # バッチ内のsrcとtgtのペアを分離\n",
    "    src_list, tgt_list = zip(*batch)\n",
    "\n",
    "    # リストをTensorに変換してスタック\n",
    "    # [batch_size, seq_len]になる\n",
    "    src_batch = torch.stack(src_list)\n",
    "    tgt_batch = torch.stack(tgt_list)\n",
    "\n",
    "    return src_batch, tgt_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce49847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# これまでのPhaseで作成したクラス・関数をインポート\n",
    "# from phase_code import Transformer, create_masks, CopyTaskDataset, collate_fn, create_padding_mask, create_look_ahead_mask\n",
    "\n",
    "class LitTransformer(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        src_vocab_size: int,\n",
    "        tgt_vocab_size: int,\n",
    "        d_model: int = 512,\n",
    "        num_layers: int = 6,\n",
    "        num_heads: int = 8,\n",
    "        d_ff: int = 2048,\n",
    "        max_len: int = 5000,\n",
    "        dropout: float = 0.1,\n",
    "        warmup_steps: int = 4000,\n",
    "        pad_idx: int = 0,\n",
    "        label_smoothing: float = 0.0\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Phase 4-6 で作成したTransformerモデル\n",
    "        self.transformer = Transformer(\n",
    "            src_vocab_size, tgt_vocab_size, d_model, num_layers, num_heads, d_ff, max_len, dropout\n",
    "        )\n",
    "        self._init_weights()\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss(\n",
    "            ignore_index=self.hparams.pad_idx,\n",
    "            label_smoothing=self.hparams.label_smoothing\n",
    "        )\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for p in self.transformer.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        # 順伝播：学習時・推論時ともに使用\n",
    "        src_mask, tgt_mask = create_masks(src, tgt, pad_idx=self.hparams.pad_idx)\n",
    "        return self.transformer(src, tgt, src_mask, tgt_mask)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        src, tgt = batch\n",
    "        tgt_input = tgt[:, :-1]\n",
    "        tgt_label = tgt[:, 1:]\n",
    "\n",
    "        logits = self(src, tgt_input)\n",
    "        \n",
    "        loss = self.criterion(\n",
    "            logits.reshape(-1, logits.size(-1)), \n",
    "            tgt_label.reshape(-1)\n",
    "        )\n",
    "        \n",
    "        # プログレスバーにLossを表示\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(\n",
    "            self.parameters(), lr=1.0, betas=(0.9, 0.98), eps=1e-9\n",
    "        )\n",
    "\n",
    "        def noam_lambda(step):\n",
    "            if step == 0: step = 1\n",
    "            d_model = self.hparams.d_model\n",
    "            warmup = self.hparams.warmup_steps\n",
    "            return (d_model ** -0.5) * min(step ** -0.5, step * (warmup ** -1.5))\n",
    "\n",
    "        scheduler = {\n",
    "            'scheduler': optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=noam_lambda),\n",
    "            'interval': 'step', \n",
    "            'frequency': 1,\n",
    "        }\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': scheduler}\n",
    "    \n",
    "    def encode(self, src, src_mask):\n",
    "        return self.transformer.encode(src, src_mask)\n",
    "    \n",
    "    def decode(self, tgt, memory, src_mask, tgt_mask):\n",
    "        return self.transformer.decode(tgt, memory, src_mask, tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0110c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode_lightning(model: LitTransformer, src: torch.Tensor, max_len: int, start_symbol: int, end_symbol: int, device: torch.device):\n",
    "    \"\"\"\n",
    "    LightningModuleを用いた推論関数\n",
    "    \"\"\"\n",
    "    model.eval() # 推論モード\n",
    "    model.to(device)\n",
    "    src = src.to(device)\n",
    "\n",
    "    # マスク作成\n",
    "    # pad_idxはハイパーパラメータから取得可能\n",
    "    pad_idx = model.hparams.pad_idx\n",
    "    src_mask = create_padding_mask(src, pad_idx).to(device)\n",
    "\n",
    "    # 1. Encode\n",
    "    with torch.no_grad():\n",
    "        memory = model.encode(src, src_mask)\n",
    "\n",
    "    # 2. Decode Loop\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type_as(src.data)\n",
    "\n",
    "    for i in range(max_len):\n",
    "        # Look-ahead Mask\n",
    "        tgt_mask = create_look_ahead_mask(ys.size(1)).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model.decode(ys, memory, src_mask, tgt_mask)\n",
    "            # 最後の単語の確率分布を取得\n",
    "            # model.transformer.fc_out にアクセス\n",
    "            prob = model.transformer.fc_out(out[:, -1])\n",
    "            \n",
    "            _, next_word = torch.max(prob, dim=1)\n",
    "            next_word = next_word.item()\n",
    "\n",
    "        # 生成された単語を追加\n",
    "        ys = torch.cat([ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
    "        \n",
    "        if next_word == end_symbol:\n",
    "            break\n",
    "            \n",
    "    return ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c0fede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. 設定 ---\n",
    "pl.seed_everything(42) # 再現性のためのシード固定\n",
    "\n",
    "SRC_VOCAB = 100\n",
    "TGT_VOCAB = 100 + 2 # <sos>, <eos>\n",
    "D_MODEL = 128\n",
    "BATCH_SIZE = 32\n",
    "MAX_LEN = 20\n",
    "EPOCHS = 30 # Lightningなら早く収束する場合が多いが、適宜調整\n",
    "\n",
    "# --- 2. データ準備 ---\n",
    "dataset = CopyTaskDataset(num_samples=2000, max_len=MAX_LEN, vocab_size=SRC_VOCAB)\n",
    "dataloader = DataLoader(\n",
    "    dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True, \n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=0 # 環境によっては0推奨\n",
    ")\n",
    "\n",
    "# --- 3. モデル初期化 ---\n",
    "model = LitTransformer(\n",
    "    src_vocab_size=SRC_VOCAB,\n",
    "    tgt_vocab_size=TGT_VOCAB,\n",
    "    d_model=D_MODEL,\n",
    "    warmup_steps=1000,\n",
    "    pad_idx=0,\n",
    "    label_smoothing=0.0\n",
    ")\n",
    "\n",
    "# --- 4. 学習実行 (Trainer) ---\n",
    "# GPUが使えるなら自動で使用\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=EPOCHS,\n",
    "    accelerator=\"auto\", \n",
    "    devices=1,\n",
    "    enable_progress_bar=True,\n",
    "    enable_checkpointing=False, # 実験用なのでチェックポイント保存なし\n",
    "    logger=False # ログファイル出力なし\n",
    ")\n",
    "\n",
    "print(\">>> Start Training with PyTorch Lightning...\")\n",
    "trainer.fit(model, dataloader)\n",
    "print(\">>> Training Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf38525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. 推論による検証 (Inference) ---\n",
    "print(\">>> Start Inference Check...\")\n",
    "\n",
    "# テストデータ: [1, 2, 3, 4, 5] という数列\n",
    "test_src = torch.tensor([[1, 2, 3, 4, 5]])\n",
    "\n",
    "# 推論実行 (<sos>=100, <eos>=101 と仮定)\n",
    "device = model.device # Trainerが割り当てたデバイスを取得\n",
    "generated = greedy_decode_lightning(\n",
    "    model, \n",
    "    test_src, \n",
    "    max_len=10, \n",
    "    start_symbol=100, \n",
    "    end_symbol=101, \n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"Input:     {test_src.cpu().numpy()}\")\n",
    "print(f\"Generated: {generated.cpu().numpy()}\")\n",
    "\n",
    "# 成功判定\n",
    "# <sos>1, 2, 3, 4, 5<eos> の形になっていれば成功\n",
    "expected_part = [1, 2, 3, 4, 5]\n",
    "gen_list = generated.cpu().numpy()[0].tolist()\n",
    "\n",
    "# <sos>を除去して比較\n",
    "if gen_list[1:len(expected_part)+1] == expected_part:\n",
    "    print(\"✅ SUCCESS: Copy Task Completed!\")\n",
    "else:\n",
    "    print(\"❌ FAILED: Incorrect output.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
